How I designed the variant track in the genome browser. Not necessarily the optimal SOP. Just what I did in practice.

1. Look at XD to get idea of:
   a. a suitable overall structure of leafs.
   b. the data we will need to drive the views.
   c. the scales at which we would need the various tracks.
   d. the structure of the focus payload.

Set up basic track
==================

It makes sens to draw the rudiments of the track before looking at the data as then when we get to the data, it can immediately go onto the screen for inspection.

It looks like we need a completely new track at zoomed in scales and the standard variant summary track when zoomed out but with dotted red lines. The dotted lines will closely resemble focus-region.eard. From Andrea's design it looks like ~64 (breakpoint 6) will be roughly the scale to switch over. Maybe ~32 (5): we can switch over later, if we need to.

First I create a basic eard track (with nothing in it) for the new scale; add it it to the ubild script; add the scale and the trigger to the track payload (ultimately this will be a task for the track API); and add relevant payloads to peregrine-generic/index.html for testing.

Rebuild files. Restart BE to pick up changes to track API contents.

May as well do a rust release build (rather than dev) to check all this as we won't be doing any rebuilding of the rust and it's nice if it's fast.

Result is, when zoomed into the right place, a blank track (with label containing rsid), when zoomed out a little, said track disappears completely.

Commit is "Variant track initial commit." on dev/0.6.0 95d9fae8

Falling back to summary track
=============================

To make the gb less confusing when working on the variant track, the next step is probably to copy up the variant summary track into the focus track. That involves pushing much of the current summary track into a function in an include file, so that we can reuse it and then setting up the relevant track in the track payload again.

After restart etc, stillhHave nothing at zoomed in level, but when zoomed out enough reverts to variant summary track. No dotted red lines for this yet. (Dotted lines should probably be different "track", anyway).

Commit is "Variant track, revert to summary when zoomed out" on dev/0.6.0 a5dcbc2a

Shore
=====

The variant track divides into three parts, which I'm going to call sky, shore, and sea (by analogy with a sunset over water). Next thing to do is to set up those containers in the style and then get the data sorted for the shore seems to make the most sense.

The only data used by the shore is a colour. It looks like the colour is consequence-based and so can probably use the same data as the summary track. That will do for the initial implementation, anyway. If that isn't correct all we'd need to do would be to change the sndpoint from "variant" (to something else currently unused) and add an endpoint in the BE server. We're going to do that for the sky and sea parts anyway, so if we need to do that for the shore as well in the future, just do the same thing here. In general it helps to iterate on the data and design, though, even if each part isn't quite correct initially. So we'll use the variant endpoint.

It's basically boxes like the the transcript track when zoomed in.

Commit is "Variant track, shore, initial" on dev/0.6.0 efc32156

Data
====

Next is probably sun. As well as this being much simpler than sea, it will give us a little prototype of those "modules" of text which are scattered all over sea. They seem to comprise a single row with variant type and allele on top and id on the bottom. Ultimately parts of these modules will be configurable, but let's display them all for now, to reduce complexity. THe challenge here is going to be the data. It looks like the sun module (the focus variant) needs the same data as all the sea modules, so we don't need a special data endpoint for focus vs non-focus. But we do need to pull this from a new variant-endpoint. Let's call it "variant-labels". We need "type", "allele", and "id". We need to use the vcfs for that, so that's the next task.

It probably makes sense to extract the data from these VCFs into bigbeds in our pipeline. We *could* add VCF support but BigBED support is already there (time-expedience) and in general it helps to reduce the data as much as possible for speed.

Looking at the module contents, it seems to make sense to do this to prerocess the VCFs.

```
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import vcfpy

reader = vcfpy.Reader.from_path('test.vcf')
for record in reader:
    start = int(record.POS)
    end = int(record.POS) + len(record.REF)
    for (id,alt) in zip(record.ID,record.ALT):
        line = [str(record.CHROM),str(start),str(end),id,alt.type,str(record.REF),alt.value]
    print("\t".join(line))
```

Rewrote in rust because the python was sloooow. Copied into the relevant data files dir, wrote the python to present the data to the GB. Did it via amazon in the first instance (quicker) using upload-to-s3.py. Wrote code on local BE server by stopping it forwarding to AWS via commenting out data forward in sources-dan.toml. When that was working copied to amazon and reenabled.

The python at the moment is simple because only a few fields required. If this ever gets complex, it should switch to using tangle, like the gene/transcript endpoints. Tangle has a setup overhead but is quick to maintain and cleaner code.

Data algorithm spec strings chosen according to the type and general pattern of the data. See dataalgorithm.py. The spec is just a forwards-polish expression defining a tree that defines functions to call to process the data.

To avoid too many potential sources of breakage, this was tested first with data-test.py till I found something which "Looked like data".

```
dan@shep:~/ensembl-dauphin-style-compiler/backend-server$ ./data-test.py http://localhost:3333/api/data/hi/
Endpoint name?  variant-labels
Ok, using endpoint variant-labels
Enter stick name (eg homo_sapiens_GCA_000001405_28:4)?  
Roughly how many bp in data?  64
Ok, nearest is scale 6 which has 64 bp
Approx centre in bp?  
Ok, nearest is index 156250 which has bp range 10000000 - 10000063


RAW DUMP
========


alts ['SYRLZ', b'\x00\x01', b'T\x00C\x00']
ids ['SZ', b'rs34407859\x00rs7695555\x00']
lengths ['NDZRL', b'\x02\x00']
refs ['SYRLZ', b'\x01\x00', b'T\x00C\x00']
starts ['NDZRL', b'\xfb8-1\x01\x08']
varieties ['SYRLZ', b'\x00\x00', b'SNV\x00']

APPROX SIZES
============


alts           4  23%
starts         4  23%
lengths        2  16%
varieties      2  16%
refs           2  13%
ids            2  10%
```

For now bolded labels after non-bolded looks difficult (I think we can only change colour ATM in the middle of a render), so I'll leave them non-bold.

Just for testing purposes I'm going to put all the IDs into sun on the screen to check the data looks right.

Looking at the data, it looks to weird to have the summary data so out of sync with the source. I hadn't realised there would be such a difference. So we should switch to getting consequence from the label source (which is a good idea anyway). So I'm going to investigating adding consequence to that payload. Where is it in the VCFs? It's in there, at least in gnomad, I can tell from grep. Looks like it's in CSQ which is in INFO. CSQ seems to be a pipe-separated field and we want position 1 (ie second position). Updated extraction code.

commit to dev/0.6.0 named "More variant track." c194a1060a

Sun
===

We now need to restrict the sun to just the focus variant and update the module. Let's update the module first as then we'll be able to temporarily see it in its various forms as we don't have sea implemented yet.

commit to dev/0.6.0 named "Sun track." fac23c5b

Sea
===

Next we need to do the sea. There are two parts to the sea: the shallow sea, where SNVs live, and the deep sea where other types live attached to fishing lines. As a first cut, let's just create the distinction and plonk everything in the shallow sea.

Things in the sea bump! That means that each needs its own leaf. Discovery: the same ID can have mulitple alt alleles. Time to regenerate the data again! Decided to stop showing detail at scale 6: too cluttered. Tweaked step to avoid to much jiggling when bumping.

TODO
====
switchable labels
bold labels
